
import os
import torch
from diffusers import StableDiffusionPipeline
from flash_attention_patch import apply_flash_attention_patch  # báº£n copy cÃ³ sáºµn trong folder model

# ==== CONFIG ====
MODEL_DIR = "/content/drive/MyDrive/Interior-stable-difusion/flash_sd15_full_patched"
UNET_STATE_PATH = f"{MODEL_DIR}/unet_flashattn_state_dict.pth"
# =================

# Kiá»ƒm tra file cáº§n thiáº¿t
assert os.path.exists(MODEL_DIR), f"âŒ KhÃ´ng tÃ¬m tháº¥y model táº¡i {MODEL_DIR}"
assert os.path.exists(UNET_STATE_PATH), f"âŒ KhÃ´ng tÃ¬m tháº¥y file UNet state_dict: {UNET_STATE_PATH}"

print("ğŸš€ Äang táº£i pipeline tá»« Hugging Face format...")
pipe = StableDiffusionPipeline.from_pretrained(
    MODEL_DIR,
    torch_dtype=torch.float16
).to("cuda")

# 1ï¸âƒ£ Patch láº¡i FlashAttention trÆ°á»›c khi load state_dict
print("ğŸ”„ Äang patch láº¡i FlashAttention vÃ o UNet...")
num_replaced = apply_flash_attention_patch(pipe.unet)
print(f"âœ… ÄÃ£ kÃ­ch hoáº¡t FlashAttention cho UNet ({num_replaced} module(s))")

# 2ï¸âƒ£ Load láº¡i trá»ng sá»‘ (Ä‘áº£m báº£o Ä‘Ãºng cáº¥u trÃºc FlashAttention)
print("ğŸ’¾ Äang load state_dict vÃ o UNet...")
state_dict = torch.load(UNET_STATE_PATH, map_location="cuda")
missing, unexpected = pipe.unet.load_state_dict(state_dict, strict=False)

if missing:
    print(f"âš ï¸ Thiáº¿u {len(missing)} keys (khÃ´ng áº£nh hÆ°á»Ÿng): {missing[:3]}...")
if unexpected:
    print(f"âš ï¸ CÃ³ {len(unexpected)} keys láº¡: {unexpected[:3]}...")

# 3ï¸âƒ£ Kiá»ƒm tra láº¡i cÃ¡c module FlashAttention
flash_modules = [
    name for name, module in pipe.unet.named_modules()
    if "flash" in module.__class__.__name__.lower()
]
print(f"âš¡ Sá»‘ module FlashAttention Ä‘ang hoáº¡t Ä‘á»™ng: {len(flash_modules)}")

if flash_modules:
    print("âœ… FlashAttention Ä‘Ã£ Ä‘Æ°á»£c load thÃ nh cÃ´ng trong UNet!")
else:
    print("âŒ KhÃ´ng phÃ¡t hiá»‡n FlashAttention!")

# 4ï¸âƒ£ Kiá»ƒm tra thá»­ pipeline hoáº¡t Ä‘á»™ng
print("ğŸ§ª Kiá»ƒm tra thá»­ inference 1 áº£nh nhá» (tÃ¹y chá»n)...")
prompt = "a modern interior design, natural light, cozy atmosphere"
image = pipe(prompt, num_inference_steps=5, height=256, width=256).images[0]
image.save(f"{MODEL_DIR}/test_flashattention_output.png")
print("âœ… ÄÃ£ táº¡o áº£nh test: test_flashattention_output.png")

print("ğŸ‰ Model Ä‘Ã£ sáºµn sÃ ng vá»›i FlashAttention!")

